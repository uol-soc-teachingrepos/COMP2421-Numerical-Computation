{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba80935",
   "metadata": {},
   "source": [
    "# Lecture 17: Quasi-Newton methods\n",
    "\n",
    "## Approximation of the derivative\n",
    "\n",
    "-   The formula $x^{(i+1)} = x^{(i)} - \\frac{f(x^{(i)})}{f'(x^{(i)})}$ requires that we are able to compute an expression for the derivative of $f(x)$.\n",
    "\n",
    "-   This may not always be possible:\n",
    "\n",
    "    -   the function $f(x)$ may be a \"black box\";\n",
    "    -   the formula for $f(x)$ may be known but may be difficult for us to differentiate.\n",
    "\n",
    "-   We can modify Newton's method by simply approximating $f'(x^{(i)})$, rather like we approximated $y'(t)$ when solving a differential equation.\n",
    "\n",
    "### Approximation of $f'(x)$\n",
    "\n",
    "-   Recall that $f'(x) = \\lim_{\\mathrm{d}x \\to 0} \\frac{f(x + \\mathrm{d}x) - f(x)}{\\mathrm{d}x}$.\n",
    "\n",
    "-   Hence we can choose a small value for $\\mathrm{d}x$ (how small?) and approximate:\n",
    "\n",
    "    $$\n",
    "    f'(x) \\approx \\frac{f(x + \\mathrm{d}x) - f(x)}{\\mathrm{d}x}.\n",
    "    $$\n",
    "\n",
    "-   This modified-Newton method then becomes\n",
    "\n",
    "    $$\n",
    "    x^{(i+1)} = x^{(i)} - \\frac{\\mathrm{d}x \\times f(x^{(i)})}{f(x^{(i)} + \\mathrm{d}x) - f(x^{(i)})}.\n",
    "    $$\n",
    "\n",
    "### The choice of $\\mathrm{d}x$\n",
    "\n",
    "-   Note that the computational cost of calculating each iterate is about the same as for Newton's method.\n",
    "\n",
    "-   What is not obvious however is what choice should be made for the value of $\\mathrm{d}x$.\n",
    "\n",
    "-   In theory (exact arithmetic) the smaller the choice of $\\mathrm{d}x$ the better the approximation of the derivative.\n",
    "\n",
    "-   In practice, however, we know that the operation of subtracting two very similar values from each other can lead to significant rounding errors when using floating point arithmetic.\n",
    "\n",
    "-   Consider the following example...\n",
    "\n",
    "## Problems with floating point arithmetic\n",
    "\n",
    "-   When $f(x) = x^3$ then $f'(x) = 3 x^2$.\n",
    "\n",
    "-   Hence, at $x_0 = 1$, $f(x_0) = 1$ and $f'(x_0) = 3$.\n",
    "\n",
    "-   Consider what happens when we approximate this with python, using finite values for $\\mathrm{d}x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffac6c92",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'hide_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     27\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:e}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapprox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:f}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:e}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrel error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:e}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m---> 29\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhide_index\u001b[49m()\u001b[38;5;241m.\u001b[39mset_caption(\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple approximation of a derivative using floating point arithmetic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'hide_index'"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**3\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    return 3 * x**2\n",
    "\n",
    "\n",
    "x = 1\n",
    "\n",
    "headers = [\"dx\", \"approx\", \"abs error\", \"rel error\"]\n",
    "data = []\n",
    "\n",
    "for e in range(4, 18, 2):\n",
    "    dx = 10**-e\n",
    "    approx = (f(x + dx) - f(x)) / dx\n",
    "    exact = df(x)\n",
    "    abs_error = abs(exact - approx)\n",
    "    rel_error = abs(exact - approx) / exact\n",
    "\n",
    "    new_data = [dx, approx, abs_error, rel_error]\n",
    "    data.append(new_data)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df.style.format(\n",
    "    formatter={\"dx\": \"{:e}\", \"approx\": \"{:f}\", \"abs error\": \"{:e}\", \"rel error\": \"{:e}\"}\n",
    ").hide_index().set_caption(\n",
    "    \"Simple approximation of a derivative using floating point arithmetic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e421bde",
   "metadata": {},
   "source": [
    "## Modified Newton's method\n",
    "\n",
    "-   Recall the definition of machine precision/unit roundoff from Lecture 3.\n",
    "\n",
    "-   The modified Newton method uses $\\mathrm{d}x = \\sqrt{eps}$.\n",
    "\n",
    "- For double precision we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "dx = np.sqrt(eps)\n",
    "\n",
    "x0 = 1.0\n",
    "df_approx = ((x0 + dx) ** 3 - x0**3) / dx\n",
    "abs_error = abs(df_approx - 3)\n",
    "rel_error = abs_error / 3\n",
    "\n",
    "print(f\"{dx=}\\n{df_approx=}\\n{abs_error=}\\n{rel_error=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4111498",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "- The example to compute the square root of 2 to a tolerance of $10^{-12}$ with starting value $1$ gives $x^* \\approx 1.4142135623731$ after 5 iterations.\n",
    "\n",
    "- The naca0012 example starting at 1 with tolerance $10^{-4}$ gives $x^* \\approx 0.76579$ after 2 iterations.\n",
    "\n",
    "- The naca0012 example starting at 1 with tolerance $10^{-5}$ gives $x^* \\approx 0.765239$ after 3 iterations.\n",
    "\n",
    "- The naca0012 example starting at 0.1 with tolerance $10^{-4}$ gives $x^* \\approx 0.03386$ after 5 iterations.\n",
    "\n",
    "In each case the performance is almost identical to the Newton method.\n",
    "\n",
    "## The secant method\n",
    "\n",
    "-   Suppose we choose $\\mathrm{d}x = x^{(i-1)} - x^{(i)}$, then we get\n",
    "\n",
    "    $$\n",
    "    f'(x^{(i)}) \\approx \\frac{f(x^{(i)} + \\mathrm{d}x) - f(x^{(i)})}{\\mathrm{d}x}\n",
    "    = \\frac{f(x^{(i)}) - f(x^{(i-1)})}{x^{(i)} - x^{(i-1)}}.\n",
    "    $$\n",
    "\n",
    "-   Newton's method then becomes\n",
    "\n",
    "    $$\n",
    "    x^{(i+1)} = x^{(i)} - f(x^{(i)}) \\frac{x^{(i)} - x^{(i-1)}}{f(x^{i}) - f(x^{(i-1)})}\n",
    "    \\left(\\approx x^{(i)} - \\frac{f(x^{(i)})}{f'(x^{(i)})} \\right).\n",
    "    $$\n",
    "\n",
    "-   Note that the main advantage of this approach over the previous modified Newton approximation is that only one new evaluation of $f(x)$ is required per iteration (apart from the very first iteration).\n",
    "\n",
    "### Pros and cons\n",
    "\n",
    "Advantages:\n",
    "\n",
    "-   $f'(x)$ is not required;\n",
    "-   only one new evaluation of $f(x)$ per iteration;\n",
    "-   still converges almost as quickly as Newton's method.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "-   *two* starting values, $x^{(0)}$ and $x^{(1)}$, are required;\n",
    "-   may require one more iteration than exact Newton (but iterations are cheaper);\n",
    "-   like Newton's method the iteration can fail to converge for some starting iterates.\n",
    "\n",
    "### Examples\n",
    "\n",
    "- The example to compute the square root of 2 starting from 1 and 1.5 to a tolerance of $10^{-4}$ gives the solution as $x^* \\approx 1.4142$ after 3 iterations.\n",
    "\n",
    "- The example to computation compound interest start from 100 and 120 to a tolerance of 0.1 gives the solution as $x^* \\approx 235.9$ after 6 iterations.\n",
    "\n",
    "- The naca0012 example starting from 1 and 0.9 to a tolerance of $10^{-4}$ gives the solution as $x^* \\approx 0.7653$ after 3 iterations.\n",
    "\n",
    "- The naca0012 example starting from 0 and 0.1 to a tolerance of $10^{-4}$ gives the solution as $x^* \\approx 0.0339$ after 5 iterations.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "- Wikipedia: [Quasi-Newton method](https://en.wikipedia.org/wiki/Quasi-Newton_method)\n",
    "- Wikipedia: [Secant method](https://en.wikipedia.org/wiki/Secant_method)\n",
    "- `scipy`: Optimization and root finding [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/optimize.html)\n",
    "\n",
    "The [slides used in the lecture](./lec17_.ipynb) are also available"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "source_map": [
   13,
   64,
   98,
   108,
   120
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}